{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import random\nimport copy\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport os\nfrom tqdm.notebook import tqdm\nfrom torch.utils.data import Dataset , DataLoader\nimport cv2\n\nfrom torchvision import transforms as T,datasets\n\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\nfrom torchvision.utils import make_grid\n\nfrom PIL import Image,ImageFilter\n\nimport warnings \n\nimport pandas as pd\nimport requests\nimport io\nimport urllib.parse\nimport pdb\nimport math\n\nimport os\nwarnings.filterwarnings(\"ignore\")","metadata":{"execution":{"iopub.status.busy":"2022-04-20T18:40:45.450766Z","iopub.execute_input":"2022-04-20T18:40:45.451177Z","iopub.status.idle":"2022-04-20T18:40:45.464085Z","shell.execute_reply.started":"2022-04-20T18:40:45.451128Z","shell.execute_reply":"2022-04-20T18:40:45.462887Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install timm # install PyTorch Image Models","metadata":{"execution":{"iopub.status.busy":"2022-04-20T18:40:45.52357Z","iopub.execute_input":"2022-04-20T18:40:45.524953Z","iopub.status.idle":"2022-04-20T18:40:53.171689Z","shell.execute_reply.started":"2022-04-20T18:40:45.524914Z","shell.execute_reply":"2022-04-20T18:40:53.17087Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import timm\nprint(timm.list_models(pretrained=True))","metadata":{"execution":{"iopub.status.busy":"2022-04-20T18:40:53.175316Z","iopub.execute_input":"2022-04-20T18:40:53.175533Z","iopub.status.idle":"2022-04-20T18:40:53.182968Z","shell.execute_reply.started":"2022-04-20T18:40:53.175508Z","shell.execute_reply":"2022-04-20T18:40:53.182273Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"SOURCE_URL = 'https://storage.googleapis.com/dm-turtle-recall/images.tar'\nIMAGE_DIR = '/kaggle/input/turtleimgs/turtle_recall/images'\nTAR_PATH = os.path.join(IMAGE_DIR, os.path.basename(SOURCE_URL))\nEXPECTED_IMAGE_COUNT = 13891\n\n\nprint(f'The total number of images is: {len(os.listdir(IMAGE_DIR))}')","metadata":{"execution":{"iopub.status.busy":"2022-04-20T18:40:53.183924Z","iopub.execute_input":"2022-04-20T18:40:53.184173Z","iopub.status.idle":"2022-04-20T18:40:53.207785Z","shell.execute_reply.started":"2022-04-20T18:40:53.184131Z","shell.execute_reply":"2022-04-20T18:40:53.207096Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"BASE_URL = 'https://storage.googleapis.com/dm-turtle-recall/'\n\n\ndef read_csv_from_web(file_name):\n  url = urllib.parse.urljoin(BASE_URL, file_name)\n  content = requests.get(url).content\n  return pd.read_csv(io.StringIO(content.decode('utf-8')))\n\n\n# Read in csv files.\ntrain = read_csv_from_web('train.csv')\ntrain[\"type\"] = \"train\"\ntest = read_csv_from_web('test.csv')\nextra = pd.read_csv(\"../input/extra-turtle-common/extra_turtle_common.csv\").sample(n=21, random_state=200).reset_index(drop=True)\nextra[\"type\"] = \"extra\"\nnew = pd.read_csv(\"../input/extra-turtle-common/extra_images_new_updated (2).csv\").sample(n=21, random_state=200).reset_index(drop=True)\nnew[\"type\"] = \"new\"\n\ntrain_all = pd.concat([train,extra,new])\nsample_submission = read_csv_from_web('sample_submission.csv')","metadata":{"execution":{"iopub.status.busy":"2022-04-20T18:40:53.209753Z","iopub.execute_input":"2022-04-20T18:40:53.210473Z","iopub.status.idle":"2022-04-20T18:40:53.48271Z","shell.execute_reply.started":"2022-04-20T18:40:53.21044Z","shell.execute_reply":"2022-04-20T18:40:53.481968Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_all.loc[(train_all.type == 'new'),'turtle_id']='new_turtle'\ntrain_all","metadata":{"execution":{"iopub.status.busy":"2022-04-20T18:40:53.48474Z","iopub.execute_input":"2022-04-20T18:40:53.485242Z","iopub.status.idle":"2022-04-20T18:40:53.500195Z","shell.execute_reply.started":"2022-04-20T18:40:53.485204Z","shell.execute_reply":"2022-04-20T18:40:53.499532Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"turtle_ids = sorted(np.unique(train_all.turtle_id))\nlabels_idx = dict(zip(turtle_ids, np.arange(len(turtle_ids))))\nlabel_lookup = {v: k for k, v in labels_idx.items()}\nnum_classes = len(labels_idx)\nassert num_classes == 101\nprint(\"number of classes:\",num_classes)\nimage_to_turtle = dict(zip(train_all.image_id, train_all.turtle_id))\n\nimage_files = [os.path.join(IMAGE_DIR, f) for f in os.listdir(IMAGE_DIR)\n              if f.split('.')[0] in train_all.image_id.values]\n\nimage_ids = [os.path.basename(f).split('.')[0] for f in image_files]\nimage_turtle_ids = [image_to_turtle[id] for id in image_ids]","metadata":{"execution":{"iopub.status.busy":"2022-04-20T18:40:53.501521Z","iopub.execute_input":"2022-04-20T18:40:53.502008Z","iopub.status.idle":"2022-04-20T18:40:55.422991Z","shell.execute_reply.started":"2022-04-20T18:40:53.501971Z","shell.execute_reply":"2022-04-20T18:40:55.422168Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#sanity check\nturtle_ids_train = ['new_turtle'] + sorted(np.unique(train.turtle_id))\nprint(turtle_ids_train == turtle_ids)\nassert turtle_ids_train == turtle_ids","metadata":{"execution":{"iopub.status.busy":"2022-04-20T18:40:55.425163Z","iopub.execute_input":"2022-04-20T18:40:55.425401Z","iopub.status.idle":"2022-04-20T18:40:55.432449Z","shell.execute_reply.started":"2022-04-20T18:40:55.425368Z","shell.execute_reply":"2022-04-20T18:40:55.431731Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load  csv\ndf_train= train_all.sample(frac=0.9,random_state=200)\ndf_validation = train_all.drop(df_train.index)\n\n#reset index for train and test \ndf_train.reset_index(drop=True, inplace=True)\ndf_validation.reset_index(drop=True, inplace=True)\n\n# define train paths and targets \ntrain_image_paths = df_train[\"image_id\"]\ntrain_targets = df_train[\"turtle_id\"]\n\n# define validation paths and targets\nval_image_paths = df_validation[\"image_id\"]\nval_targets = df_validation[\"turtle_id\"]\n\n#define test paths \ntest_image_paths = test[\"image_id\"]","metadata":{"execution":{"iopub.status.busy":"2022-04-20T18:40:55.43351Z","iopub.execute_input":"2022-04-20T18:40:55.433794Z","iopub.status.idle":"2022-04-20T18:40:55.469224Z","shell.execute_reply.started":"2022-04-20T18:40:55.433756Z","shell.execute_reply":"2022-04-20T18:40:55.468554Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns\nimages_per_turtle = pd.value_counts(df_train['turtle_id'])\nprint(len(images_per_turtle))\nplt.figure(figsize=(3, 21))\nsns.barplot(x=images_per_turtle, y=images_per_turtle.index,\n            palette='Blues_r', orient='horizontal')\nplt.show()\n\nimport seaborn as sns\nimages_per_turtle = pd.value_counts(df_validation['turtle_id'])\nprint(len(images_per_turtle))\nplt.figure(figsize=(3, 21))\nsns.barplot(x=images_per_turtle, y=images_per_turtle.index,\n            palette='Blues_r', orient='horizontal')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-20T18:40:55.470262Z","iopub.execute_input":"2022-04-20T18:40:55.470565Z","iopub.status.idle":"2022-04-20T18:40:58.449218Z","shell.execute_reply.started":"2022-04-20T18:40:55.47053Z","shell.execute_reply":"2022-04-20T18:40:58.448542Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"params = {\n    \"image_size\": 256,\n    \"model\": \"resnet152\",\n    \"device\": \"cuda\",\n    \"lr\": 0.001,\n    \"batch_size\": 16,\n    \"num_workers\": 0,\n    \"epochs\": 150\n}","metadata":{"execution":{"iopub.status.busy":"2022-04-20T18:40:58.451501Z","iopub.execute_input":"2022-04-20T18:40:58.452976Z","iopub.status.idle":"2022-04-20T18:40:58.457371Z","shell.execute_reply.started":"2022-04-20T18:40:58.452933Z","shell.execute_reply":"2022-04-20T18:40:58.45661Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_size = 256\ntrain_transform = A.Compose(\n    [\n        A.Resize(params[\"image_size\"],params[\"image_size\"]),\n        #A.CenterCrop(224,224),\n        A.MedianBlur(blur_limit=5, always_apply=False, p=0.5),\n        A.IAASharpen(alpha=(0.2, 0.5), lightness=(0.5, 1.0), always_apply=False, p=0.5),\n        A.HueSaturationValue(hue_shift_limit=0.2,sat_shift_limit=0.2,val_shift_limit=0.2,p=0.5),\n        A.RandomBrightnessContrast(brightness_limit=(-0.1,0.1),contrast_limit=(-0.1, 0.1),p=0.5),\n        A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.05, rotate_limit=15, p=0.7),\n        A.Flip(),\n        A.FancyPCA(),\n        A.GaussNoise(),\n        A.IAAEmboss(),\n        A.ISONoise(),\n        A.CLAHE(clip_limit=4.0, tile_grid_size=(8, 8), always_apply=False, p=0.5),\n        A.ColorJitter (brightness=0.5, contrast=0.5, saturation=0.2, hue=0.2, always_apply=False, p=0.5),  \n        #A.RandomCrop(height=128, width=128),\n        A.RandomRotate90(p=0.5),\n        A.RGBShift(r_shift_limit=15, g_shift_limit=15, b_shift_limit=15, p=0.5),\n        A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), max_pixel_value=255.0, p=1.0),\n#         ToTensorV2(),\n    ]\n)\n\n#Augmentation is not done for test/validation data.\nval_transform = A.Compose(\n    [\n        A.Resize(params[\"image_size\"],params[\"image_size\"]),\n        A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), max_pixel_value=255.0, p=1.0),\n#         ToTensorV2(),\n    ]\n)\n\n#Augmentation is not done for test/validation data.\ntest_transform = A.Compose(\n    [\n        A.Resize(params[\"image_size\"],params[\"image_size\"]),\n        A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), max_pixel_value=255.0, p=1.0),\n        ToTensorV2(),\n    ]\n)","metadata":{"execution":{"iopub.status.busy":"2022-04-20T18:40:58.458485Z","iopub.execute_input":"2022-04-20T18:40:58.459862Z","iopub.status.idle":"2022-04-20T18:40:58.473552Z","shell.execute_reply.started":"2022-04-20T18:40:58.459804Z","shell.execute_reply":"2022-04-20T18:40:58.47278Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from PIL import Image, ImageEnhance, ImageOps\nimport random\n\n\nclass ShearX(object):\n    def __init__(self, fillcolor=(128, 128, 128)):\n        self.fillcolor = fillcolor\n\n    def __call__(self, x, magnitude):\n        return x.transform(\n            x.size, Image.AFFINE, (1, magnitude * random.choice([-1, 1]), 0, 0, 1, 0),\n            Image.BICUBIC, fillcolor=self.fillcolor)\n\n\nclass ShearY(object):\n    def __init__(self, fillcolor=(128, 128, 128)):\n        self.fillcolor = fillcolor\n\n    def __call__(self, x, magnitude):\n        return x.transform(\n            x.size, Image.AFFINE, (1, 0, 0, magnitude * random.choice([-1, 1]), 1, 0),\n            Image.BICUBIC, fillcolor=self.fillcolor)\n\n\nclass TranslateX(object):\n    def __init__(self, fillcolor=(128, 128, 128)):\n        self.fillcolor = fillcolor\n\n    def __call__(self, x, magnitude):\n        return x.transform(\n            x.size, Image.AFFINE, (1, 0, magnitude * x.size[0] * random.choice([-1, 1]), 0, 1, 0),\n            fillcolor=self.fillcolor)\n\n\nclass TranslateY(object):\n    def __init__(self, fillcolor=(128, 128, 128)):\n        self.fillcolor = fillcolor\n\n    def __call__(self, x, magnitude):\n        return x.transform(\n            x.size, Image.AFFINE, (1, 0, 0, 0, 1, magnitude * x.size[1] * random.choice([-1, 1])),\n            fillcolor=self.fillcolor)\n\n\nclass Rotate(object):\n    def __call__(self, x, magnitude):\n        rot = x.convert(\"RGBA\").rotate(magnitude * random.choice([-1, 1]))\n        return Image.composite(rot, Image.new(\"RGBA\", rot.size, (128,) * 4), rot).convert(x.mode)\n\n\nclass Color(object):\n    def __call__(self, x, magnitude):\n        return ImageEnhance.Color(x).enhance(1 + magnitude * random.choice([-1, 1]))\n\n\nclass Posterize(object):\n    def __call__(self, x, magnitude):\n        return ImageOps.posterize(x, magnitude)\n\n\nclass Solarize(object):\n    def __call__(self, x, magnitude):\n        return ImageOps.solarize(x, magnitude)\n\n\nclass Contrast(object):\n    def __call__(self, x, magnitude):\n        return ImageEnhance.Contrast(x).enhance(1 + magnitude * random.choice([-1, 1]))\n\n\nclass Sharpness(object):\n    def __call__(self, x, magnitude):\n        return ImageEnhance.Sharpness(x).enhance(1 + magnitude * random.choice([-1, 1]))\n\n\nclass Brightness(object):\n    def __call__(self, x, magnitude):\n        return ImageEnhance.Brightness(x).enhance(1 + magnitude * random.choice([-1, 1]))\n\n\nclass AutoContrast(object):\n    def __call__(self, x, magnitude):\n        return ImageOps.autocontrast(x)\n\n\nclass Equalize(object):\n    def __call__(self, x, magnitude):\n        return ImageOps.equalize(x)\n\n\nclass Invert(object):\n    def __call__(self, x, magnitude):\n        return ImageOps.invert(x)","metadata":{"execution":{"iopub.status.busy":"2022-04-20T18:40:58.475942Z","iopub.execute_input":"2022-04-20T18:40:58.476366Z","iopub.status.idle":"2022-04-20T18:40:58.497606Z","shell.execute_reply.started":"2022-04-20T18:40:58.476329Z","shell.execute_reply":"2022-04-20T18:40:58.496862Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ImageNetPolicy(object):\n    \"\"\" Randomly choose one of the best 24 Sub-policies on ImageNet.\n        Example:\n        >>> policy = ImageNetPolicy()\n        >>> transformed = policy(image)\n        Example as a PyTorch Transform:\n        >>> transform = transforms.Compose([\n        >>>     transforms.Resize(256),\n        >>>     ImageNetPolicy(),\n        >>>     transforms.ToTensor()])\n    \"\"\"\n    def __init__(self, fillcolor=(128, 128, 128)):\n        self.policies = [\n            SubPolicy(0.4, \"posterize\", 8, 0.6, \"rotate\", 9, fillcolor),\n            SubPolicy(0.6, \"solarize\", 5, 0.6, \"autocontrast\", 5, fillcolor),\n            SubPolicy(0.8, \"equalize\", 8, 0.6, \"equalize\", 3, fillcolor),\n            SubPolicy(0.6, \"posterize\", 7, 0.6, \"posterize\", 6, fillcolor),\n            SubPolicy(0.4, \"equalize\", 7, 0.2, \"solarize\", 4, fillcolor),\n\n            SubPolicy(0.4, \"equalize\", 4, 0.8, \"rotate\", 8, fillcolor),\n            SubPolicy(0.6, \"solarize\", 3, 0.6, \"equalize\", 7, fillcolor),\n            SubPolicy(0.8, \"posterize\", 5, 1.0, \"equalize\", 2, fillcolor),\n            SubPolicy(0.2, \"rotate\", 3, 0.6, \"solarize\", 8, fillcolor),\n            SubPolicy(0.6, \"equalize\", 8, 0.4, \"posterize\", 6, fillcolor),\n\n            SubPolicy(0.8, \"rotate\", 8, 0.4, \"color\", 0, fillcolor),\n            SubPolicy(0.4, \"rotate\", 9, 0.6, \"equalize\", 2, fillcolor),\n            SubPolicy(0.0, \"equalize\", 7, 0.8, \"equalize\", 8, fillcolor),\n            SubPolicy(0.6, \"invert\", 4, 1.0, \"equalize\", 8, fillcolor),\n            SubPolicy(0.6, \"color\", 4, 1.0, \"contrast\", 8, fillcolor),\n\n            SubPolicy(0.8, \"rotate\", 8, 1.0, \"color\", 2, fillcolor),\n            SubPolicy(0.8, \"color\", 8, 0.8, \"solarize\", 7, fillcolor),\n            SubPolicy(0.4, \"sharpness\", 7, 0.6, \"invert\", 8, fillcolor),\n            SubPolicy(0.6, \"shearX\", 5, 1.0, \"equalize\", 9, fillcolor),\n            SubPolicy(0.4, \"color\", 0, 0.6, \"equalize\", 3, fillcolor),\n\n            SubPolicy(0.4, \"equalize\", 7, 0.2, \"solarize\", 4, fillcolor),\n            SubPolicy(0.6, \"solarize\", 5, 0.6, \"autocontrast\", 5, fillcolor),\n            SubPolicy(0.6, \"invert\", 4, 1.0, \"equalize\", 8, fillcolor),\n            SubPolicy(0.6, \"color\", 4, 1.0, \"contrast\", 8, fillcolor),\n            SubPolicy(0.8, \"equalize\", 8, 0.6, \"equalize\", 3, fillcolor)\n        ]\n\n    def __call__(self, image):\n        policy_idx = random.randint(0, len(self.policies) - 1)\n        return self.policies[policy_idx](image)\n\n    def __repr__(self):\n        return \"AutoAugment ImageNet Policy\"\n    \n######################################################################    \n    \nclass SubPolicy(object):\n    def __init__(self, p1, operation1, magnitude_idx1, p2, operation2, magnitude_idx2, fillcolor=(128, 128, 128)):\n        ranges = {\n            \"shearX\": np.linspace(0, 0.3, 10),\n            \"shearY\": np.linspace(0, 0.3, 10),\n            \"translateX\": np.linspace(0, 150 / 331, 10),\n            \"translateY\": np.linspace(0, 150 / 331, 10),\n            \"rotate\": np.linspace(0, 30, 10),\n            \"color\": np.linspace(0.0, 0.9, 10),\n            \"posterize\": np.round(np.linspace(8, 4, 10), 0).astype(np.int),\n            \"solarize\": np.linspace(256, 0, 10),\n            \"contrast\": np.linspace(0.0, 0.9, 10),\n            \"sharpness\": np.linspace(0.0, 0.9, 10),\n            \"brightness\": np.linspace(0.0, 0.9, 10),\n            \"autocontrast\": [0] * 10,\n            \"equalize\": [0] * 10,\n            \"invert\": [0] * 10\n        }\n\n        func = {\n            \"shearX\": ShearX(fillcolor=fillcolor),\n            \"shearY\": ShearY(fillcolor=fillcolor),\n            \"translateX\": TranslateX(fillcolor=fillcolor),\n            \"translateY\": TranslateY(fillcolor=fillcolor),\n            \"rotate\": Rotate(),\n            \"color\": Color(),\n            \"posterize\": Posterize(),\n            \"solarize\": Solarize(),\n            \"contrast\": Contrast(),\n            \"sharpness\": Sharpness(),\n            \"brightness\": Brightness(),\n            \"autocontrast\": AutoContrast(),\n            \"equalize\": Equalize(),\n            \"invert\": Invert()\n        }\n\n        self.p1 = p1\n        self.operation1 = func[operation1]\n        self.magnitude1 = ranges[operation1][magnitude_idx1]\n        self.p2 = p2\n        self.operation2 = func[operation2]\n        self.magnitude2 = ranges[operation2][magnitude_idx2]\n\n    def __call__(self, image):\n        if random.random() < self.p1:\n            image = self.operation1(image, self.magnitude1)\n        if random.random() < self.p2:\n            image = self.operation2(image, self.magnitude2)\n        return image","metadata":{"execution":{"iopub.status.busy":"2022-04-20T18:40:58.498895Z","iopub.execute_input":"2022-04-20T18:40:58.499168Z","iopub.status.idle":"2022-04-20T18:40:58.525633Z","shell.execute_reply.started":"2022-04-20T18:40:58.499137Z","shell.execute_reply":"2022-04-20T18:40:58.524861Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# #define a custom dataset \nfrom PIL import Image \nimport PIL\nfrom torchvision import transforms ,datasets\n\nimport tensorflow as tf\nclass NewCustomDataset(Dataset):\n    def __init__(self, image_paths, targets=None, transform=None, train=False):\n        self.image_paths=image_paths\n        self.targets=targets\n        self.transform=transform\n        self.train=train\n        \n    def __len__(self):\n        return len(self.image_paths)\n    \n    def __getitem__(self, idx):\n        \n        image_filepath = '/kaggle/input/turtleimgs/turtle_recall/images/'+self.image_paths[idx]+'.JPG'\n        #image = cv2.imread(image_filepath)  \n        #image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        image = PIL.Image.open(image_filepath)\n       \n        if self.targets is not None :\n            label = self.targets[idx]\n            int_label = labels_idx[label]\n            if self.transform is not None :\n                if self.train:\n                    policy = ImageNetPolicy()\n                    aug_img = np.array(policy(image))\n                    transform = transforms.ToTensor()\n                    image = self.transform(image=aug_img)[\"image\"]\n                    image = transform(image)\n                else:\n                    transform = transforms.ToTensor()\n                    image = self.transform(image=np.array(image))[\"image\"]\n                    image = transform(image)\n            return image ,int_label\n        else : \n            label = 0\n            if self.transform is not None :\n                image = np.array(image)\n                image = self.transform(image=image)[\"image\"]\n            return image , label\ntrain_dataset  = NewCustomDataset(train_image_paths, train_targets , transform=train_transform, train=True)\nval_dataset    = NewCustomDataset(val_image_paths , val_targets , transform=val_transform, train=False)\ntest_dataset   = NewCustomDataset(test_image_paths, targets=None, transform=test_transform, train=False)","metadata":{"execution":{"iopub.status.busy":"2022-04-20T18:40:58.526908Z","iopub.execute_input":"2022-04-20T18:40:58.527214Z","iopub.status.idle":"2022-04-20T18:40:58.540397Z","shell.execute_reply.started":"2022-04-20T18:40:58.527178Z","shell.execute_reply":"2022-04-20T18:40:58.539662Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def visualize_augmentations(dataset, idx=9999, samples=10, cols=5):\n    dataset = copy.deepcopy(dataset)\n#     dataset.transform = A.Compose([t for t in dataset.transform if not isinstance(t, (A.Normalize, ToTensorV2))])\n    rows = samples // cols\n    figure, ax = plt.subplots(nrows=rows, ncols=cols, figsize=(12, 6))\n    for i in range(samples):\n        image,_ = dataset[i]\n        image = np.transpose(image, (2,1,0)) \n        ax.ravel()[i].imshow(image)\n        ax.ravel()[i].set_axis_off()\n    plt.tight_layout()\n    plt.show()\nrandom.seed(52)\n# print(\"validation\")\n# visualize_augmentations(val_dataset)\nprint(\"train\")\nvisualize_augmentations(train_dataset)","metadata":{"execution":{"iopub.status.busy":"2022-04-20T18:40:58.54147Z","iopub.execute_input":"2022-04-20T18:40:58.54178Z","iopub.status.idle":"2022-04-20T18:40:59.809226Z","shell.execute_reply.started":"2022-04-20T18:40:58.541745Z","shell.execute_reply":"2022-04-20T18:40:59.807701Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_loader = DataLoader(\n    train_dataset, batch_size=params[\"batch_size\"], shuffle=True, num_workers=params[\"num_workers\"], pin_memory=True,\n)\n\nprint(\"No. of batches in trainloader:{}\".format(len(train_loader))) #Trainset Size:  5216 / batch_size: 16 = 326(No. of batches in trainloader) \nprint(\"No. of Total examples:{}\".format(len(train_loader.dataset)))\n\nval_loader = DataLoader(\n    val_dataset, batch_size=params[\"batch_size\"], shuffle=False, num_workers=params[\"num_workers\"], pin_memory=True,\n)\n\nprint(\"No. of batches in valloader:{}\".format(len(val_loader))) #Trainset Size:  5216 / batch_size: 16 = 326(No. of batches in trainloader) \nprint(\"No. of Total examples:{}\".format(len(val_loader.dataset)))\n\ntest_loader = DataLoader(\n    test_dataset, batch_size=params[\"batch_size\"], shuffle=False, num_workers=params[\"num_workers\"], pin_memory=True,\n)\n\nprint(\"No. of batches in testloader:{}\".format(len(test_loader))) #Trainset Size:  5216 / batch_size: 16 = 326(No. of batches in trainloader) \nprint(\"No. of Total examples:{}\".format(len(test_loader.dataset)))","metadata":{"execution":{"iopub.status.busy":"2022-04-20T18:25:51.227487Z","iopub.execute_input":"2022-04-20T18:25:51.228197Z","iopub.status.idle":"2022-04-20T18:25:51.239967Z","shell.execute_reply.started":"2022-04-20T18:25:51.228156Z","shell.execute_reply":"2022-04-20T18:25:51.239258Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import timm # PyTorch Image Models\n# freeze the first 6 layers of model\nmodel = timm.create_model(params[\"model\"],pretrained=True) #load pretrained model\n\nn_features = model.fc.in_features\n\nct = 0\nfor child in model.children():\n    ct += 1\n    if ct < 7:\n        for param in child.parameters():\n            param.requires_grad = False\n\n# #we are updating it as a 2-class classifier:\nmodel.fc = nn.Sequential(\n    nn.Linear(in_features=n_features, out_features=256), #1792 is the orginal in_features\n    nn.ReLU(), #ReLu to be the activation function\n    nn.Dropout(p=0.2),\n    nn.Linear(in_features=256, out_features=101),\n)\nmodel","metadata":{"execution":{"iopub.status.busy":"2022-04-20T18:36:16.469631Z","iopub.execute_input":"2022-04-20T18:36:16.469906Z","iopub.status.idle":"2022-04-20T18:36:18.967373Z","shell.execute_reply.started":"2022-04-20T18:36:16.469876Z","shell.execute_reply":"2022-04-20T18:36:18.966656Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Trainer():\n    \n    def __init__(self,criterion = None,optimizer = None,schedular = None):\n        \n        self.criterion = criterion\n        self.optimizer = optimizer\n        self.schedular = schedular\n        self.valid_min_loss = np.Inf\n        self.best_epoch = 0\n\n    def accuracy(self,outputs, labels):\n        _, preds = torch.max(outputs, dim=1)\n        return torch.tensor(torch.sum(preds == labels).item() / len(preds))\n    \n    def train_batch_loop(self,model,trainloader):\n        \n        train_loss = 0.0\n        train_acc = 0.0\n        \n        for images,labels in tqdm(trainloader): \n            \n            images = images.to(device)  \n            labels = labels.to(device)\n            \n            logits = model(images)\n            loss = self.criterion(logits,labels)\n            \n            self.optimizer.zero_grad()\n            loss.backward()\n            self.optimizer.step()\n            \n            train_loss += loss.item()\n            train_acc += self.accuracy(logits,labels)\n            \n        return train_loss / len(trainloader), train_acc / len(trainloader) \n\n    \n    def valid_batch_loop(self,model,validloader):\n        \n        valid_loss = 0.0\n        valid_acc = 0.0\n        \n        for images,labels in tqdm(validloader):\n            \n            # move the data to CPU\n            images = images.to(device) \n            labels = labels.to(device)\n            \n            logits = model(images)\n            loss = self.criterion(logits,labels)\n            \n            valid_loss += loss.item()\n            valid_acc += self.accuracy(logits,labels)\n            \n            del images\n            del labels\n            \n        return valid_loss / len(validloader), valid_acc / len(validloader)\n    \n    \n    def fit(self,model,trainloader,validloader,epochs):\n        \n        self.valid_min_loss = np.Inf \n        \n        for i in range(epochs):\n            \n            model.train() # this turn on dropout\n            avg_train_loss, avg_train_acc = self.train_batch_loop(model,trainloader) ###\n            \n            model.eval()  # this turns off the dropout lapyer and batch norm\n            avg_valid_loss, avg_valid_acc = self.valid_batch_loop(model,validloader) ###\n            \n            if avg_valid_loss <= self.valid_min_loss :\n                print(\"Valid_loss decreased {} --> {}\".format(self.valid_min_loss,avg_valid_loss))\n                torch.save(model.state_dict(),'{}Model_{}_{}.pt'.format(params[\"model\"],i,avg_valid_loss))\n                self.valid_min_loss = avg_valid_loss\n                self.best_epoch = i\n                \n            print(\"Epoch : {} Train Loss : {:.6f} Train Acc : {:.6f}\".format(i+1, avg_train_loss, avg_train_acc))\n            print(\"Epoch : {} Valid Loss : {:.6f} Valid Acc : {:.6f}\".format(i+1, avg_valid_loss, avg_valid_acc))\n    \n    def get_valid_min_loss(self):\n        return self.valid_min_loss\n    \n    def get_best_epoch(self):\n        return self.best_epoch","metadata":{"execution":{"iopub.status.busy":"2022-04-19T14:08:50.07866Z","iopub.execute_input":"2022-04-19T14:08:50.078906Z","iopub.status.idle":"2022-04-19T14:08:50.099462Z","shell.execute_reply.started":"2022-04-19T14:08:50.078879Z","shell.execute_reply":"2022-04-19T14:08:50.098529Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"On which device we are on:{}\".format(device))","metadata":{"execution":{"iopub.status.busy":"2022-04-19T14:08:50.100532Z","iopub.execute_input":"2022-04-19T14:08:50.101558Z","iopub.status.idle":"2022-04-19T14:08:50.119621Z","shell.execute_reply.started":"2022-04-19T14:08:50.101507Z","shell.execute_reply":"2022-04-19T14:08:50.118785Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"criterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(),lr = params[\"lr\"])\nmodel.to(device)\ntrainer = Trainer(criterion,optimizer)\ntrainer.fit(model,train_loader,val_loader,epochs = params[\"epochs\"])","metadata":{"execution":{"iopub.status.busy":"2022-04-19T14:08:50.12045Z","iopub.execute_input":"2022-04-19T14:08:50.120718Z","iopub.status.idle":"2022-04-19T14:12:24.12878Z","shell.execute_reply.started":"2022-04-19T14:08:50.120685Z","shell.execute_reply":"2022-04-19T14:12:24.127197Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"avg_valid_loss = trainer.get_valid_min_loss()\ni = trainer.get_best_epoch()\n\nmodel.load_state_dict(torch.load('./{}Model_{}_{}.pt'.format(params[\"model\"],i,avg_valid_loss)))\nmodel.eval()\ntrainer = Trainer(criterion,optimizer)\n\navg_test_loss, avg_test_acc = trainer.valid_batch_loop(model,test_loader)\n\nprint(\"Test Loss : {}\".format(avg_test_loss))\nprint(\"Test Acc : {}\".format(avg_test_acc))","metadata":{"execution":{"iopub.status.busy":"2022-04-19T14:12:24.129878Z","iopub.status.idle":"2022-04-19T14:12:24.130207Z","shell.execute_reply.started":"2022-04-19T14:12:24.130038Z","shell.execute_reply":"2022-04-19T14:12:24.130061Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def inference(data_loader, model):\n    model.eval()\n\n    activation = nn.Softmax(dim=1)\n    all_predicts, all_confs, all_targets = [], [], []\n\n    with torch.no_grad():\n        for i, (img,target) in enumerate(tqdm(data_loader)):\n            #input_, target = data['image'], data['target']\n            \n            output = model(img.cuda())\n            output = activation(output)\n\n            confs, predicts = torch.topk(output, 5)\n            all_confs.append(confs)\n            all_predicts.append(predicts)\n\n            if target is not None:\n                all_targets.append(target)\n\n    predicts = torch.cat(all_predicts)\n    confs = torch.cat(all_confs)\n    targets = torch.cat(all_targets) if len(all_targets) else None\n\n    return predicts, confs, targets\n\npredicts_gpu, confs_gpu, _ = inference(test_loader, model)\npredicts, confs = predicts_gpu.cpu().numpy(), confs_gpu.cpu().numpy()","metadata":{"execution":{"iopub.status.busy":"2022-04-19T14:12:24.132371Z","iopub.status.idle":"2022-04-19T14:12:24.132985Z","shell.execute_reply.started":"2022-04-19T14:12:24.132706Z","shell.execute_reply":"2022-04-19T14:12:24.132735Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#labels_idx\n\nkey_list = list(labels_idx.keys())\nval_list = list(labels_idx.values())\n\nnew_list = []\nnew_sublist = []\nrow_idx =0 \ncol_idx = 0\nfor row in predicts : \n    for val in row : \n        #print(val)\n        position = val_list.index(val)\n        new_val = key_list[position]\n        new_sublist.append(new_val)\n    new_list.append(new_sublist)\n    new_sublist = []\n\nidx = 0\nfor sub in new_list:\n    sub.insert(0,test[\"image_id\"][idx])\n    idx += 1","metadata":{"execution":{"iopub.status.busy":"2022-04-19T14:12:24.134677Z","iopub.status.idle":"2022-04-19T14:12:24.13515Z","shell.execute_reply.started":"2022-04-19T14:12:24.134895Z","shell.execute_reply":"2022-04-19T14:12:24.134921Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.DataFrame(new_list, columns = ['image_id', 'prediction1','prediction2','prediction3','prediction4','prediction5'])\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-19T14:12:24.136591Z","iopub.status.idle":"2022-04-19T14:12:24.137062Z","shell.execute_reply.started":"2022-04-19T14:12:24.13681Z","shell.execute_reply":"2022-04-19T14:12:24.136835Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.to_csv(\"submission.csv\",index=False)","metadata":{"execution":{"iopub.status.busy":"2022-04-19T14:12:24.138897Z","iopub.status.idle":"2022-04-19T14:12:24.139814Z","shell.execute_reply.started":"2022-04-19T14:12:24.139509Z","shell.execute_reply":"2022-04-19T14:12:24.139545Z"},"trusted":true},"execution_count":null,"outputs":[]}]}