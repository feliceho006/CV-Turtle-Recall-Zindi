{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7pkR01SXK1tS"
   },
   "source": [
    "Import all the libraries required for this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "UBHHqPy2lE0L"
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.backends.cudnn as cudnn\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import pandas as pd\n",
    "import requests\n",
    "import io\n",
    "import urllib.parse\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import functools\n",
    "from PIL import Image  # Image utilities.\n",
    "import tqdm\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import imageio as io_temp\n",
    "from skimage.transform import resize\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score, classification_report, confusion_matrix\n",
    "\n",
    "\n",
    "cudnn.benchmark = True\n",
    "plt.ion()   # interactive mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_8KkHItyK7EI"
   },
   "source": [
    "Downloading the dataset from online resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wA_fHgODZqE0",
    "outputId": "10e1a7e5-d36a-43ba-b4ee-8e3e84a23f18"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of images is: 13891\n"
     ]
    }
   ],
   "source": [
    "SOURCE_URL = 'https://storage.googleapis.com/dm-turtle-recall/images.tar'\n",
    "IMAGE_DIR = './turtle_recall/images'\n",
    "TAR_PATH = os.path.join(IMAGE_DIR, os.path.basename(SOURCE_URL))\n",
    "EXPECTED_IMAGE_COUNT = 13891\n",
    "\n",
    "%sx mkdir --parents \"{IMAGE_DIR}\"\n",
    "if len(os.listdir(IMAGE_DIR)) != EXPECTED_IMAGE_COUNT:\n",
    "  %sx wget --no-check-certificate -O \"{TAR_PATH}\" \"{SOURCE_URL}\"\n",
    "  %sx tar --extract --file=\"{TAR_PATH}\" --directory=\"{IMAGE_DIR}\"\n",
    "  %sx rm \"{TAR_PATH}\"\n",
    "\n",
    "print(f'The total number of images is: {len(os.listdir(IMAGE_DIR))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "uapoX2flaGEG"
   },
   "outputs": [],
   "source": [
    "BASE_URL = 'https://storage.googleapis.com/dm-turtle-recall/'\n",
    "\n",
    "\n",
    "def read_csv_from_web(file_name):\n",
    "  url = urllib.parse.urljoin(BASE_URL, file_name)\n",
    "  content = requests.get(url).content\n",
    "  return pd.read_csv(io.StringIO(content.decode('utf-8')))\n",
    "\n",
    "# Read in csv files.\n",
    "train = read_csv_from_web('train.csv')\n",
    "test = read_csv_from_web('test.csv')\n",
    "extra = read_csv_from_web('extra_images.csv')\n",
    "sample_submission = read_csv_from_web('sample_submission.csv')\n",
    "\n",
    "# Convert image_location strings to lowercase.\n",
    "for df in [train, test]:\n",
    "  df.image_location = df.image_location.apply(lambda x: x.lower())\n",
    "  assert set(df.image_location.unique()) == set(['left', 'right', 'top'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "d-czhL74aKCA",
    "outputId": "5c1a7294-41c2-4cfa-9ba4-97a28ab8ef2f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>image_location</th>\n",
       "      <th>turtle_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID_2RK4WLN8</td>\n",
       "      <td>top</td>\n",
       "      <td>t_id_VP2NW7aV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID_VVW0QXLX</td>\n",
       "      <td>left</td>\n",
       "      <td>t_id_qZ0iZYsC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID_RVATH2HZ</td>\n",
       "      <td>right</td>\n",
       "      <td>t_id_3b65X5Lw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ID_2GB90GPS</td>\n",
       "      <td>left</td>\n",
       "      <td>t_id_YjXYTCGC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ID_LM6S0B1M</td>\n",
       "      <td>top</td>\n",
       "      <td>t_id_d6aYXtor</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      image_id image_location      turtle_id\n",
       "0  ID_2RK4WLN8            top  t_id_VP2NW7aV\n",
       "1  ID_VVW0QXLX           left  t_id_qZ0iZYsC\n",
       "2  ID_RVATH2HZ          right  t_id_3b65X5Lw\n",
       "3  ID_2GB90GPS           left  t_id_YjXYTCGC\n",
       "4  ID_LM6S0B1M            top  t_id_d6aYXtor"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "xFMvi9VQaLGY",
    "outputId": "1c10a986-485b-435d-f6b7-d880841a8931"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>image_location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID_6NEDKOYZ</td>\n",
       "      <td>top</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID_57QZ4S9N</td>\n",
       "      <td>left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID_OCGGJS5X</td>\n",
       "      <td>left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ID_R2993S3S</td>\n",
       "      <td>top</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ID_2E011NB0</td>\n",
       "      <td>left</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      image_id image_location\n",
       "0  ID_6NEDKOYZ            top\n",
       "1  ID_57QZ4S9N           left\n",
       "2  ID_OCGGJS5X           left\n",
       "3  ID_R2993S3S            top\n",
       "4  ID_2E011NB0           left"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "xwy3KtkEhbTR",
    "outputId": "a606c03e-4464-4436-b96b-c990d1079f7c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>turtle_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID_Y0KYE5XD</td>\n",
       "      <td>t_id_he7JTQxO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID_8JTIQ4UI</td>\n",
       "      <td>t_id_he7JTQxO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID_LSXPZYSN</td>\n",
       "      <td>t_id_he7JTQxO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ID_SHZ2HDSP</td>\n",
       "      <td>t_id_he7JTQxO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ID_6TOFB06E</td>\n",
       "      <td>t_id_xry0Yg2j</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      image_id      turtle_id\n",
       "0  ID_Y0KYE5XD  t_id_he7JTQxO\n",
       "1  ID_8JTIQ4UI  t_id_he7JTQxO\n",
       "2  ID_LSXPZYSN  t_id_he7JTQxO\n",
       "3  ID_SHZ2HDSP  t_id_he7JTQxO\n",
       "4  ID_6TOFB06E  t_id_xry0Yg2j"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extra.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gJ3QJpFuaNQR",
    "outputId": "b2045b5b-ffc1-43a0-d9ca-eb70cf7f7597"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2145, 3), (490, 2), (10658, 2))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, test.shape, extra.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_mTpIevBaPsn",
    "outputId": "8f5b4c80-7d89-4cad-95a8-7a7f007da452"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 100 unique turtles in the train set.\n",
      "There are 2231 unique turtles in the train set.\n"
     ]
    }
   ],
   "source": [
    "print(f\"There are {train.turtle_id.nunique()} unique turtles in the train set.\")\n",
    "print(f\"There are {extra.turtle_id.nunique()} unique turtles in the train set.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "KlgyH88OaRDk"
   },
   "outputs": [],
   "source": [
    "train_images_per_turtle = pd.value_counts(train['turtle_id'])\n",
    "extra_images_per_turtle = pd.value_counts(extra['turtle_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V_j6qTcUaSZo",
    "outputId": "df70639f-259e-46a2-8689-0f801c1e0b56"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "t_id_ROFhVsy2    77\n",
       "t_id_hRzOoJ2t    68\n",
       "t_id_VP2NW7aV    58\n",
       "t_id_Kf73l69A    57\n",
       "t_id_dVQ4x3wz    47\n",
       "                 ..\n",
       "t_id_Dv4O8bOM    10\n",
       "t_id_4XiPKIk7    10\n",
       "t_id_OqU1NWEA     9\n",
       "t_id_p77GDtzg     9\n",
       "t_id_J5dngbNA     8\n",
       "Name: turtle_id, Length: 100, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images_per_turtle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7FNRSo-LhzbH",
    "outputId": "09c6389a-0d26-45c4-cb8a-2384be2342cd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "t_id_dVQ4x3wz    68\n",
       "t_id_UkwhEKp2    41\n",
       "t_id_YjXYTCGC    40\n",
       "t_id_XN39nRhf    40\n",
       "t_id_FFUgltSC    37\n",
       "                 ..\n",
       "t_id_31E0Dcfq     1\n",
       "t_id_wITmkTkm     1\n",
       "t_id_2Yn71r7R     1\n",
       "t_id_1Lr4vRbM     1\n",
       "t_id_DbmclTcj     1\n",
       "Name: turtle_id, Length: 2231, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extra_images_per_turtle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nbN_rb3ELPDS"
   },
   "source": [
    "Capturing all the turtle IDs and assigning a number to each turtle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "hg0Zy1Mx4mrs"
   },
   "outputs": [],
   "source": [
    "ls = pd.unique(train['turtle_id'])\n",
    "classes = {}\n",
    "for i in range(len(ls)):\n",
    "    classes[ls[i]] = i\n",
    "class_names = classes\n",
    "ls2 = pd.unique(train['image_location'])\n",
    "locations = {}\n",
    "for i in range(len(ls2)):\n",
    "    locations[ls2[i]] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "RCI84TQY27e3"
   },
   "outputs": [],
   "source": [
    "num_classes = len(class_names)\n",
    "num_locations = len(['left', 'right', 'top'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dkrKdadd3O7K",
    "outputId": "8b0b98ab-0883-4b20-eea4-335cf1a80fe1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1716, 2) (214, 2) (215, 2) (1716,) (214,) (215,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train[['image_id','image_location']], train['turtle_id'], test_size=0.20, random_state=42, stratify=train['turtle_id'])\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.50, random_state=42, stratify=y_test)\n",
    "\n",
    "print(X_train.shape, X_test.shape, X_val.shape ,y_train.shape, y_test.shape, y_val.shape)\n",
    "\n",
    "train_ds = pd.concat([X_train, y_train], axis=1)\n",
    "train_ds['type'] = \"train\"\n",
    "test_ds = pd.concat([X_test, y_test], axis=1)\n",
    "test_ds['type'] = \"test\"\n",
    "val_ds = pd.concat([X_val, y_val], axis=1)\n",
    "val_ds['type'] = \"val\"\n",
    "extra_ds = extra\n",
    "extra_ds['type'] = \"extra\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "yI3brvFt4msD"
   },
   "outputs": [],
   "source": [
    "dataset_sizes = {'train': len(train_ds), 'test': len(test_ds), 'val': len(val_ds), 'extra': len(extra_ds)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "cM28Kivt-CgO",
    "outputId": "6a2b3e58-f0ca-411c-82f6-51e53eea64b7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>image_location</th>\n",
       "      <th>turtle_id</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>708</th>\n",
       "      <td>ID_UC0NFKIH</td>\n",
       "      <td>left</td>\n",
       "      <td>t_id_UVQa4BMz</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>ID_IZB1O90H</td>\n",
       "      <td>right</td>\n",
       "      <td>t_id_2QmcRkNj</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>614</th>\n",
       "      <td>ID_L4O6H0WC</td>\n",
       "      <td>top</td>\n",
       "      <td>t_id_8b8sprYe</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011</th>\n",
       "      <td>ID_BUYIHPE9</td>\n",
       "      <td>left</td>\n",
       "      <td>t_id_tjWepji1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>761</th>\n",
       "      <td>ID_2HBGMZLT</td>\n",
       "      <td>right</td>\n",
       "      <td>t_id_BI99coHt</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1126</th>\n",
       "      <td>ID_3JHL0XDW</td>\n",
       "      <td>left</td>\n",
       "      <td>t_id_AOWArhGb</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>697</th>\n",
       "      <td>ID_DBYS9YUA</td>\n",
       "      <td>right</td>\n",
       "      <td>t_id_uJXT7dGu</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>ID_XAO3YF62</td>\n",
       "      <td>top</td>\n",
       "      <td>t_id_D0gA44av</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>ID_P7LXRA4M</td>\n",
       "      <td>left</td>\n",
       "      <td>t_id_4XiPKIk7</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ID_8VXV1HDO</td>\n",
       "      <td>top</td>\n",
       "      <td>t_id_hRzOoJ2t</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1716 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         image_id image_location      turtle_id   type\n",
       "708   ID_UC0NFKIH           left  t_id_UVQa4BMz  train\n",
       "59    ID_IZB1O90H          right  t_id_2QmcRkNj  train\n",
       "614   ID_L4O6H0WC            top  t_id_8b8sprYe  train\n",
       "2011  ID_BUYIHPE9           left  t_id_tjWepji1  train\n",
       "761   ID_2HBGMZLT          right  t_id_BI99coHt  train\n",
       "...           ...            ...            ...    ...\n",
       "1126  ID_3JHL0XDW           left  t_id_AOWArhGb  train\n",
       "697   ID_DBYS9YUA          right  t_id_uJXT7dGu  train\n",
       "165   ID_XAO3YF62            top  t_id_D0gA44av  train\n",
       "52    ID_P7LXRA4M           left  t_id_4XiPKIk7  train\n",
       "6     ID_8VXV1HDO            top  t_id_hRzOoJ2t  train\n",
       "\n",
       "[1716 rows x 4 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "MvO5FbwtQ51o",
    "outputId": "7abdb3eb-10a3-4c97-d0f7-c7e58f6f6d91"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>turtle_id</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID_Y0KYE5XD</td>\n",
       "      <td>t_id_he7JTQxO</td>\n",
       "      <td>extra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID_8JTIQ4UI</td>\n",
       "      <td>t_id_he7JTQxO</td>\n",
       "      <td>extra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID_LSXPZYSN</td>\n",
       "      <td>t_id_he7JTQxO</td>\n",
       "      <td>extra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ID_SHZ2HDSP</td>\n",
       "      <td>t_id_he7JTQxO</td>\n",
       "      <td>extra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ID_6TOFB06E</td>\n",
       "      <td>t_id_xry0Yg2j</td>\n",
       "      <td>extra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10653</th>\n",
       "      <td>ID_PLYDY39S</td>\n",
       "      <td>t_id_9YXAIhtI</td>\n",
       "      <td>extra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10654</th>\n",
       "      <td>ID_1EJCP0DF</td>\n",
       "      <td>t_id_9YXAIhtI</td>\n",
       "      <td>extra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10655</th>\n",
       "      <td>ID_WXIGYROR</td>\n",
       "      <td>t_id_ajlHbN2F</td>\n",
       "      <td>extra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10656</th>\n",
       "      <td>ID_UAU4GUNK</td>\n",
       "      <td>t_id_ajlHbN2F</td>\n",
       "      <td>extra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10657</th>\n",
       "      <td>ID_Z02Y4N4V</td>\n",
       "      <td>t_id_ajlHbN2F</td>\n",
       "      <td>extra</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10658 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          image_id      turtle_id   type\n",
       "0      ID_Y0KYE5XD  t_id_he7JTQxO  extra\n",
       "1      ID_8JTIQ4UI  t_id_he7JTQxO  extra\n",
       "2      ID_LSXPZYSN  t_id_he7JTQxO  extra\n",
       "3      ID_SHZ2HDSP  t_id_he7JTQxO  extra\n",
       "4      ID_6TOFB06E  t_id_xry0Yg2j  extra\n",
       "...            ...            ...    ...\n",
       "10653  ID_PLYDY39S  t_id_9YXAIhtI  extra\n",
       "10654  ID_1EJCP0DF  t_id_9YXAIhtI  extra\n",
       "10655  ID_WXIGYROR  t_id_ajlHbN2F  extra\n",
       "10656  ID_UAU4GUNK  t_id_ajlHbN2F  extra\n",
       "10657  ID_Z02Y4N4V  t_id_ajlHbN2F  extra\n",
       "\n",
       "[10658 rows x 3 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extra_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "1LBlW_K1_fOD"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:1: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.concat([train_ds,test_ds,val_ds,extra_ds], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "prucJ_Ct_wDn",
    "outputId": "7d8d2f11-2c67-4a45-e559-b233d1d18315"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>image_location</th>\n",
       "      <th>turtle_id</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>708</th>\n",
       "      <td>ID_UC0NFKIH</td>\n",
       "      <td>left</td>\n",
       "      <td>t_id_UVQa4BMz</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>ID_IZB1O90H</td>\n",
       "      <td>right</td>\n",
       "      <td>t_id_2QmcRkNj</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>614</th>\n",
       "      <td>ID_L4O6H0WC</td>\n",
       "      <td>top</td>\n",
       "      <td>t_id_8b8sprYe</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011</th>\n",
       "      <td>ID_BUYIHPE9</td>\n",
       "      <td>left</td>\n",
       "      <td>t_id_tjWepji1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>761</th>\n",
       "      <td>ID_2HBGMZLT</td>\n",
       "      <td>right</td>\n",
       "      <td>t_id_BI99coHt</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10653</th>\n",
       "      <td>ID_PLYDY39S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>t_id_9YXAIhtI</td>\n",
       "      <td>extra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10654</th>\n",
       "      <td>ID_1EJCP0DF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>t_id_9YXAIhtI</td>\n",
       "      <td>extra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10655</th>\n",
       "      <td>ID_WXIGYROR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>t_id_ajlHbN2F</td>\n",
       "      <td>extra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10656</th>\n",
       "      <td>ID_UAU4GUNK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>t_id_ajlHbN2F</td>\n",
       "      <td>extra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10657</th>\n",
       "      <td>ID_Z02Y4N4V</td>\n",
       "      <td>NaN</td>\n",
       "      <td>t_id_ajlHbN2F</td>\n",
       "      <td>extra</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12803 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          image_id image_location      turtle_id   type\n",
       "708    ID_UC0NFKIH           left  t_id_UVQa4BMz  train\n",
       "59     ID_IZB1O90H          right  t_id_2QmcRkNj  train\n",
       "614    ID_L4O6H0WC            top  t_id_8b8sprYe  train\n",
       "2011   ID_BUYIHPE9           left  t_id_tjWepji1  train\n",
       "761    ID_2HBGMZLT          right  t_id_BI99coHt  train\n",
       "...            ...            ...            ...    ...\n",
       "10653  ID_PLYDY39S            NaN  t_id_9YXAIhtI  extra\n",
       "10654  ID_1EJCP0DF            NaN  t_id_9YXAIhtI  extra\n",
       "10655  ID_WXIGYROR            NaN  t_id_ajlHbN2F  extra\n",
       "10656  ID_UAU4GUNK            NaN  t_id_ajlHbN2F  extra\n",
       "10657  ID_Z02Y4N4V            NaN  t_id_ajlHbN2F  extra\n",
       "\n",
       "[12803 rows x 4 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "Xv1uasWbAEcZ"
   },
   "outputs": [],
   "source": [
    "dataset['image_id'] = IMAGE_DIR + \"/\" + dataset['image_id'].astype(str) + \".JPG\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DPaVsAr4LZm5"
   },
   "source": [
    "Replacing the turtle IDs with numbers for easier training by the deep learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "l99rkFbytN-n"
   },
   "outputs": [],
   "source": [
    "dataset['turtle_id'] = dataset['turtle_id'].map(classes)\n",
    "dataset['image_location'] = dataset['image_location'].map(locations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "0E1kopnqZSCC"
   },
   "outputs": [],
   "source": [
    "dataset.to_csv('./dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "NIoMcNXwAYuZ"
   },
   "outputs": [],
   "source": [
    "train_ds = dataset.loc[dataset['type'] == \"train\"]\n",
    "test_ds = dataset.loc[dataset['type'] == \"test\"]\n",
    "val_ds = dataset.loc[dataset['type'] == \"val\"]\n",
    "extra_ds = dataset.loc[dataset['type'] == \"extra\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "5awhf_IrAx1-",
    "outputId": "e9cd7895-0ce5-4c78-9b94-7823168c25f3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>image_location</th>\n",
       "      <th>turtle_id</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>708</th>\n",
       "      <td>./turtle_recall/images/ID_UC0NFKIH.JPG</td>\n",
       "      <td>1.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>./turtle_recall/images/ID_IZB1O90H.JPG</td>\n",
       "      <td>2.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>614</th>\n",
       "      <td>./turtle_recall/images/ID_L4O6H0WC.JPG</td>\n",
       "      <td>0.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011</th>\n",
       "      <td>./turtle_recall/images/ID_BUYIHPE9.JPG</td>\n",
       "      <td>1.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>761</th>\n",
       "      <td>./turtle_recall/images/ID_2HBGMZLT.JPG</td>\n",
       "      <td>2.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1126</th>\n",
       "      <td>./turtle_recall/images/ID_3JHL0XDW.JPG</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>697</th>\n",
       "      <td>./turtle_recall/images/ID_DBYS9YUA.JPG</td>\n",
       "      <td>2.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>./turtle_recall/images/ID_XAO3YF62.JPG</td>\n",
       "      <td>0.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>./turtle_recall/images/ID_P7LXRA4M.JPG</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>./turtle_recall/images/ID_8VXV1HDO.JPG</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1716 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    image_id  image_location  turtle_id   type\n",
       "708   ./turtle_recall/images/ID_UC0NFKIH.JPG             1.0       37.0  train\n",
       "59    ./turtle_recall/images/ID_IZB1O90H.JPG             2.0       44.0  train\n",
       "614   ./turtle_recall/images/ID_L4O6H0WC.JPG             0.0       43.0  train\n",
       "2011  ./turtle_recall/images/ID_BUYIHPE9.JPG             1.0       38.0  train\n",
       "761   ./turtle_recall/images/ID_2HBGMZLT.JPG             2.0       23.0  train\n",
       "...                                      ...             ...        ...    ...\n",
       "1126  ./turtle_recall/images/ID_3JHL0XDW.JPG             1.0       25.0  train\n",
       "697   ./turtle_recall/images/ID_DBYS9YUA.JPG             2.0       54.0  train\n",
       "165   ./turtle_recall/images/ID_XAO3YF62.JPG             0.0       63.0  train\n",
       "52    ./turtle_recall/images/ID_P7LXRA4M.JPG             1.0       26.0  train\n",
       "6     ./turtle_recall/images/ID_8VXV1HDO.JPG             0.0        6.0  train\n",
       "\n",
       "[1716 rows x 4 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "Y31GxL6FuusE",
    "outputId": "a5931f2d-6550-458f-ea73-c81f474886d7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>image_location</th>\n",
       "      <th>turtle_id</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./turtle_recall/images/ID_Y0KYE5XD.JPG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>extra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>./turtle_recall/images/ID_8JTIQ4UI.JPG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>extra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>./turtle_recall/images/ID_LSXPZYSN.JPG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>extra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>./turtle_recall/images/ID_SHZ2HDSP.JPG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>extra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>./turtle_recall/images/ID_6TOFB06E.JPG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>extra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10653</th>\n",
       "      <td>./turtle_recall/images/ID_PLYDY39S.JPG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>extra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10654</th>\n",
       "      <td>./turtle_recall/images/ID_1EJCP0DF.JPG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>extra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10655</th>\n",
       "      <td>./turtle_recall/images/ID_WXIGYROR.JPG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>extra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10656</th>\n",
       "      <td>./turtle_recall/images/ID_UAU4GUNK.JPG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>extra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10657</th>\n",
       "      <td>./turtle_recall/images/ID_Z02Y4N4V.JPG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>extra</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10658 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     image_id  image_location  turtle_id  \\\n",
       "0      ./turtle_recall/images/ID_Y0KYE5XD.JPG             NaN        NaN   \n",
       "1      ./turtle_recall/images/ID_8JTIQ4UI.JPG             NaN        NaN   \n",
       "2      ./turtle_recall/images/ID_LSXPZYSN.JPG             NaN        NaN   \n",
       "3      ./turtle_recall/images/ID_SHZ2HDSP.JPG             NaN        NaN   \n",
       "4      ./turtle_recall/images/ID_6TOFB06E.JPG             NaN        NaN   \n",
       "...                                       ...             ...        ...   \n",
       "10653  ./turtle_recall/images/ID_PLYDY39S.JPG             NaN        NaN   \n",
       "10654  ./turtle_recall/images/ID_1EJCP0DF.JPG             NaN        NaN   \n",
       "10655  ./turtle_recall/images/ID_WXIGYROR.JPG             NaN        NaN   \n",
       "10656  ./turtle_recall/images/ID_UAU4GUNK.JPG             NaN        NaN   \n",
       "10657  ./turtle_recall/images/ID_Z02Y4N4V.JPG             NaN        NaN   \n",
       "\n",
       "        type  \n",
       "0      extra  \n",
       "1      extra  \n",
       "2      extra  \n",
       "3      extra  \n",
       "4      extra  \n",
       "...      ...  \n",
       "10653  extra  \n",
       "10654  extra  \n",
       "10655  extra  \n",
       "10656  extra  \n",
       "10657  extra  \n",
       "\n",
       "[10658 rows x 4 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extra_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JET34lPoLhYY"
   },
   "source": [
    "Creating a Dataloader for our dataset which can be used for pytorch. This only makes use of the image data and the turtle ID. The turtles head orientation is not used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "id": "4585evc5PSr9"
   },
   "outputs": [],
   "source": [
    "class TurtleDataset(Dataset):\n",
    "    \"\"\"Turtle dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, csv_file, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.csv = csv_file\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.csv)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        img_name = self.csv.iloc[idx, 0]\n",
    "        image = io_temp.imread(img_name)\n",
    "        details = self.csv.iloc[idx, 1:]\n",
    "        details = np.array([details])\n",
    "        details = details[:1]\n",
    "        sample = {'image': image, 'image_orientation': details[0][0], 'turtle_id': details[0][1], 'image_id': img_name}\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "id": "PLXnh8E9RbHE"
   },
   "outputs": [],
   "source": [
    "def show_pics(image, image_orientation, turtle_id):\n",
    "    plt.imshow(image)\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 466
    },
    "id": "AhW-n5mmP1ng",
    "outputId": "ce5dbbd4-016d-46e8-b9d7-f8296cbf398b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (743, 876, 3) 37.0 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7fd963abf9b0>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 961, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 941, in _shutdown_workers\n",
      "    w.join()\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/process.py\", line 124, in join\n",
      "    res = self._popen.wait(timeout)\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/popen_fork.py\", line 50, in wait\n",
      "    return self.poll(os.WNOHANG if timeout == 0.0 else 0)\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/popen_fork.py\", line 28, in poll\n",
      "    pid, sts = os.waitpid(self.pid, flag)\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "show_pics() got an unexpected keyword argument 'image_id'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-99-b4ad731145e5>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     12\u001B[0m     \u001B[0max\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mset_title\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'Sample #{}'\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mformat\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mi\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     13\u001B[0m     \u001B[0max\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0maxis\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'off'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 14\u001B[0;31m     \u001B[0mshow_pics\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m**\u001B[0m\u001B[0msample\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     15\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     16\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mi\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;36m3\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mTypeError\u001B[0m: show_pics() got an unexpected keyword argument 'image_id'"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "face_dataset = TurtleDataset(csv_file=train_ds)\n",
    "\n",
    "fig = plt.figure()\n",
    "\n",
    "for i in range(len(face_dataset)):\n",
    "    sample = face_dataset[i]\n",
    "\n",
    "    print(i, sample['image'].shape, sample['turtle_id'], sample['image_orientation'])\n",
    "\n",
    "    ax = plt.subplot(1, 4, i + 1)\n",
    "    plt.tight_layout()\n",
    "    ax.set_title('Sample #{}'.format(i))\n",
    "    ax.axis('off')\n",
    "    show_pics(**sample)\n",
    "\n",
    "    if i == 3:\n",
    "        plt.show()\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0lH42myNLtbc"
   },
   "source": [
    "Rescale helps reformat the image by changing its dimensions and cropping it to allow it to be used as an input in our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "id": "QNDcMnZDbaWo"
   },
   "outputs": [],
   "source": [
    "class Rescale(object):\n",
    "    \"\"\"Rescale the image in a sample to a given size.\n",
    "\n",
    "    Args:\n",
    "        output_size (tuple or int): Desired output size. If tuple, output is\n",
    "            matched to output_size. If int, smaller of image edges is matched\n",
    "            to output_size keeping aspect ratio the same.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, output_size = 224):\n",
    "        assert isinstance(output_size, (int, tuple))\n",
    "        self.output_size = output_size\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        #image, turtle_id = sample['image'], sample['image_orientation']#,  sample['turtle_id'] \n",
    "        image, image_orientation = sample['image'], sample['image_orientation']\n",
    "\n",
    "        h, w = image.shape[:2]\n",
    "        crop_size = min(w, h)\n",
    "        crop = image[(h - crop_size) // 2 : (h + crop_size) // 2, (w - crop_size) // 2 : (w + crop_size) // 2]\n",
    "        img = resize(crop, (self.output_size, self.output_size))\n",
    "\n",
    "        # return {'image': img, 'turtle_id': turtle_id}\n",
    "        #return [img.transpose((2,0,1)).astype(np.double),turtle_id]\n",
    "        return [img.transpose((2,0,1)).astype(np.double),image_orientation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Rescale_extra(object):\n",
    "    \"\"\"Rescale the image in a sample to a given size.\n",
    "\n",
    "    Args:\n",
    "        output_size (tuple or int): Desired output size. If tuple, output is\n",
    "            matched to output_size. If int, smaller of image edges is matched\n",
    "            to output_size keeping aspect ratio the same.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, output_size = 224):\n",
    "        assert isinstance(output_size, (int, tuple))\n",
    "        self.output_size = output_size\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        #image, turtle_id = sample['image'], sample['image_orientation']#,  sample['turtle_id'] \n",
    "        image, image_orientation = sample['image'], sample['image_id']\n",
    "\n",
    "        h, w = image.shape[:2]\n",
    "        crop_size = min(w, h)\n",
    "        crop = image[(h - crop_size) // 2 : (h + crop_size) // 2, (w - crop_size) // 2 : (w + crop_size) // 2]\n",
    "        img = resize(crop, (self.output_size, self.output_size))\n",
    "\n",
    "        # return {'image': img, 'turtle_id': turtle_id}\n",
    "        #return [img.transpose((2,0,1)).astype(np.double),turtle_id]\n",
    "        return [img.transpose((2,0,1)).astype(np.double),image_orientation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "id": "9_mv2FI1bfht"
   },
   "outputs": [],
   "source": [
    "scale = Rescale(256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "id": "p9_xZtOxgiN7"
   },
   "outputs": [],
   "source": [
    "train_transformed_dataset = TurtleDataset(csv_file=train_ds,\n",
    "                                               transform=transforms.Compose([\n",
    "                                               Rescale(256)\n",
    "                                           ]))\n",
    "test_transformed_dataset = TurtleDataset(csv_file=test_ds,\n",
    "                                               transform=transforms.Compose([\n",
    "                                               Rescale(256)\n",
    "                                           ]))\n",
    "val_transformed_dataset = TurtleDataset(csv_file=val_ds,\n",
    "                                               transform=transforms.Compose([\n",
    "                                               Rescale(256)\n",
    "                                           ]))\n",
    "extra_transformed_dataset = TurtleDataset(csv_file=extra_ds,\n",
    "                                              transform=transforms.Compose([\n",
    "                                              Rescale_extra(256)\n",
    "                                           ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "id": "f3wuRDMeg7lm"
   },
   "outputs": [],
   "source": [
    "dataloaders = {#'train' : DataLoader(train_transformed_dataset, batch_size=16,\n",
    "#                         shuffle=True, num_workers=2),\n",
    "              'test' : DataLoader(test_transformed_dataset, batch_size=16,\n",
    "                        shuffle=True, num_workers=2),\n",
    "#               'val' : DataLoader(val_transformed_dataset, batch_size=16,\n",
    "#                         shuffle=True, num_workers=2),\n",
    "              'extra': DataLoader(extra_transformed_dataset, batch_size=16,\n",
    "                        shuffle=True, num_workers=2)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 163
    },
    "id": "pm-kCmbVwcbe",
    "outputId": "efdbb904-433b-4d1a-bfaa-0d125cebfdc1"
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'train'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-34-5ea594de7044>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     13\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     14\u001B[0m \u001B[0;31m# Get a batch of training data\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 15\u001B[0;31m \u001B[0minputs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mclasses\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnext\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0miter\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdataloaders\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'train'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     16\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     17\u001B[0m \u001B[0;31m# Make a grid from batch\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyError\u001B[0m: 'train'"
     ]
    }
   ],
   "source": [
    "def imshow(inp, title=None):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
    "\n",
    "\n",
    "# Get a batch of training data\n",
    "inputs, classes = next(iter(dataloaders['train']))\n",
    "\n",
    "# Make a grid from batch\n",
    "out = torchvision.utils.make_grid(inputs)\n",
    "\n",
    "imshow(out, title=classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RdDxDGF2L-Vk"
   },
   "source": [
    "train_model is a funciton to train any model with any criterion and optimizer. We can change the model input with other pretrained models to experiment further!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "20kaKUCABb4K"
   },
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                #inputs = inputs.type(torch.LongTensor)\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.type(torch.LongTensor)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs.float())\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "VypSd5Lqt9Ol"
   },
   "outputs": [],
   "source": [
    "def visualize_model(model, num_images=6):\n",
    "    was_training = model.training\n",
    "    model.eval()\n",
    "    images_so_far = 0\n",
    "    fig = plt.figure()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (inputs, labels) in enumerate(dataloaders['val']):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs.float())\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            for j in range(inputs.size()[0]):\n",
    "                images_so_far += 1\n",
    "                ax = plt.subplot(num_images//2, 2, images_so_far)\n",
    "                ax.axis('off')\n",
    "                ax.set_title('predicted: {}'.format(class_names[preds[j]]))\n",
    "                imshow(inputs.cpu().data[j])\n",
    "\n",
    "                if images_so_far == num_images:\n",
    "                    model.train(mode=was_training)\n",
    "                    return\n",
    "        model.train(mode=was_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "PlBjxA7uuJ3_"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kMo9qm_4zRN8",
    "outputId": "be1d0b8e-afb3-4aea-858e-7a2540484246"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 66,
     "referenced_widgets": [
      "d981bb1c5ff7480abbb6a0c403e601ce",
      "3fec97c2e3fd4470af3f4e00428c4527",
      "ed525b1b427546ae825539c05fab21a0",
      "1b7ae868c17049e3a1cebc21ab53966b",
      "f02c2f2dabe64f17bdeec157f4c9f95e",
      "ea2c9d960fe645218cad041c2d83f0ee",
      "e3e98fa77f314f6dafbbfe1f3766fdac",
      "91347326eb814707856e232e7811c35d",
      "96f8936f045a4405b008defe22c972ad",
      "fcd828c6e46c489f80208d266255acf9",
      "41349625475a4f9d878e831b9c70e619"
     ]
    },
    "id": "qPizP55RuCm1",
    "outputId": "dcae69cd-d1d1-4f65-bec8-dc1a8d29871c"
   },
   "outputs": [],
   "source": [
    "model_ft = models.resnet18(pretrained=True, progress=True) ### Can change this to try out other models available \n",
    "num_ftrs = model_ft.fc.in_features\n",
    "# Here the size of each output sample is set to 2.\n",
    "# Alternatively, it can be generalized to nn.Linear(num_ftrs, len(class_names)).\n",
    "model_ft.fc = nn.Linear(num_ftrs, num_locations)\n",
    "\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SEaD7GDYyT8N",
    "outputId": "539f3f1d-14c9-4668-d0cb-29358868b97c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/3\n",
      "----------\n",
      "train Loss: 0.5039 Acc: 0.8024\n",
      "val Loss: 0.2317 Acc: 0.9302\n",
      "\n",
      "Epoch 1/3\n",
      "----------\n",
      "train Loss: 0.2036 Acc: 0.9359\n",
      "val Loss: 0.2220 Acc: 0.9256\n",
      "\n",
      "Epoch 2/3\n",
      "----------\n",
      "train Loss: 0.1159 Acc: 0.9645\n",
      "val Loss: 0.2334 Acc: 0.9349\n",
      "\n",
      "Epoch 3/3\n",
      "----------\n",
      "train Loss: 0.0666 Acc: 0.9843\n",
      "val Loss: 0.2320 Acc: 0.9488\n",
      "\n",
      "Training complete in 15m 38s\n",
      "Best val Acc: 0.948837\n"
     ]
    }
   ],
   "source": [
    "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n",
    "                       num_epochs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model_ft.state_dict(),\"turtle_image_location.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet18(pretrained=True, progress=True)\n",
    "num_ftrs = model.fc.in_features\n",
    "# Here the size of each output sample is set to 2.\n",
    "# Alternatively, it can be generalized to nn.Linear(num_ftrs, len(class_names)).\n",
    "model.fc = nn.Linear(num_ftrs, num_locations)\n",
    "model.load_state_dict(torch.load(\"turtle_image_location.pth\"))\n",
    "model.eval()\n",
    "model_ft = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "8XNRD2C9D3aZ"
   },
   "outputs": [],
   "source": [
    "def apk(actual, predicted, k=5):\n",
    "  \"\"\"Computes the average precision at k.\n",
    "\n",
    "  Args:\n",
    "    actual: The turtle ID to be predicted.\n",
    "    predicted : A list of predicted turtle IDs (order does matter).\n",
    "    k : The maximum number of predicted elements.\n",
    "\n",
    "  Returns:\n",
    "    The average precision at k.\n",
    "  \"\"\"\n",
    "  if len(predicted) > k:\n",
    "    predicted = predicted[:k]\n",
    "\n",
    "  score = 0.0\n",
    "  num_hits = 0.0\n",
    "\n",
    "  for i, p in enumerate(predicted):\n",
    "    if p == actual and p not in predicted[:i]:\n",
    "      num_hits += 1.0\n",
    "      score += num_hits / (i + 1.0)\n",
    "\n",
    "  return score\n",
    "\n",
    "\n",
    "def mapk(actual, predicted, k=5):\n",
    "  \"\"\" Computes the mean average precision at k.\n",
    "\n",
    "    The turtle ID at actual[i] will be used to score predicted[i][:k] so order\n",
    "    matters throughout!\n",
    "\n",
    "    actual: A list of the true turtle IDs to score against.\n",
    "    predicted: A list of lists of predicted turtle IDs.\n",
    "    k: The size of the window to score within.\n",
    "\n",
    "    Returns:\n",
    "      The mean average precision at k.\n",
    "  \"\"\"\n",
    "  return np.mean([apk(a, p, k) for a, p in zip(actual, predicted)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "1NRgDhoCBdRW"
   },
   "outputs": [],
   "source": [
    "def test_model(model, criterion, optimizer, scheduler):\n",
    "\n",
    "    model.eval()   # Set model to evaluate mode\n",
    "\n",
    "    t_output = []\n",
    "    t_pred = []\n",
    "    y_test = []\n",
    "    top_k = []\n",
    "    # Iterate over data.\n",
    "    for inputs, labels in dataloaders['test']:\n",
    "        # inputs = inputs.type(torch.DoubleTensor)\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.type(torch.LongTensor)\n",
    "        labels = labels.to(device)\n",
    "        y_test.append(labels)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward\n",
    "        # track history if only in train\n",
    "        with torch.set_grad_enabled(True):\n",
    "            outputs = model(inputs.float())\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            loss = criterion(outputs, labels)\n",
    "            t_output.append(outputs)\n",
    "            t_pred.append(preds)\n",
    "            temp1, temp2 = outputs.topk(1)\n",
    "            top_k.append(temp2)\n",
    "    \n",
    "    y_test = torch.cat(y_test).cpu().detach().numpy() \n",
    "    y_test_num = torch.cat(t_pred).cpu().detach().numpy() \n",
    "    y_pred = torch.cat(top_k).cpu().detach().numpy() \n",
    "    mapk_result = mapk(y_test, y_pred, k=1)\n",
    "    print(\"With real set labels, our mapk with k=1 is\", mapk_result)\n",
    "    print('\\nConfusion Matrix')\n",
    "    conf_mt = confusion_matrix(y_test_num, y_test)\n",
    "    print(conf_mt)\n",
    "    plt.matshow(conf_mt)\n",
    "    plt.show()\n",
    "    print('\\nClassification Report')\n",
    "    print(classification_report(y_test_num, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "telFbCPoCPwT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With real set labels, our mapk with k=5 is 0.9299065420560748\n",
      "\n",
      "Confusion Matrix\n",
      "[[65  2  1]\n",
      " [ 2 65  1]\n",
      " [ 5  4 69]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.96      0.93        68\n",
      "           1       0.92      0.96      0.94        68\n",
      "           2       0.97      0.88      0.93        78\n",
      "\n",
      "    accuracy                           0.93       214\n",
      "   macro avg       0.93      0.93      0.93       214\n",
      "weighted avg       0.93      0.93      0.93       214\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "id": "75p0fmF6yapP"
   },
   "outputs": [],
   "source": [
    "def pred(model, criterion, optimizer, scheduler):\n",
    "\n",
    "    model.eval()   # Set model to evaluate mode\n",
    "\n",
    "    t_id = []\n",
    "    t_pred = []\n",
    "    y_test = []\n",
    "    top_k = []\n",
    "    # Iterate over data.\n",
    "    for inputs,labels in DataLoader(extra_transformed_dataset, batch_size=16, shuffle=True, num_workers=2):\n",
    "        # inputs = inputs.type(torch.DoubleTensor)\n",
    "        inputs = inputs.to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward\n",
    "        # track history if only in train\n",
    "        with torch.set_grad_enabled(True):\n",
    "            outputs = model(inputs.float())\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            t_id += labels\n",
    "            t_pred += preds.tolist()\n",
    "\n",
    "\n",
    "    return t_pred,t_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 165
    },
    "id": "bSldXSA53d7V",
    "outputId": "c8860633-e61f-4a8b-989b-4cd61acd0433",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred, y_id = pred(model_ft, criterion, optimizer_ft, exp_lr_scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({\"image_id\" : y_id, \"image_orientation\" : y_pred})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"predicted_head_orientation.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# with open(\"nice.pickle\", 'wb') as f:\n",
    "#     pickle.dump(y_pred, f)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Pytorch_turtle_extras.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "1b7ae868c17049e3a1cebc21ab53966b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fcd828c6e46c489f80208d266255acf9",
      "placeholder": "​",
      "style": "IPY_MODEL_41349625475a4f9d878e831b9c70e619",
      "value": " 44.7M/44.7M [00:00&lt;00:00, 126MB/s]"
     }
    },
    "3fec97c2e3fd4470af3f4e00428c4527": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ea2c9d960fe645218cad041c2d83f0ee",
      "placeholder": "​",
      "style": "IPY_MODEL_e3e98fa77f314f6dafbbfe1f3766fdac",
      "value": "100%"
     }
    },
    "41349625475a4f9d878e831b9c70e619": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "91347326eb814707856e232e7811c35d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "96f8936f045a4405b008defe22c972ad": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d981bb1c5ff7480abbb6a0c403e601ce": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_3fec97c2e3fd4470af3f4e00428c4527",
       "IPY_MODEL_ed525b1b427546ae825539c05fab21a0",
       "IPY_MODEL_1b7ae868c17049e3a1cebc21ab53966b"
      ],
      "layout": "IPY_MODEL_f02c2f2dabe64f17bdeec157f4c9f95e"
     }
    },
    "e3e98fa77f314f6dafbbfe1f3766fdac": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ea2c9d960fe645218cad041c2d83f0ee": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ed525b1b427546ae825539c05fab21a0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_91347326eb814707856e232e7811c35d",
      "max": 46830571,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_96f8936f045a4405b008defe22c972ad",
      "value": 46830571
     }
    },
    "f02c2f2dabe64f17bdeec157f4c9f95e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fcd828c6e46c489f80208d266255acf9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}