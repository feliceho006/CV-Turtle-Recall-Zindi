{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7pkR01SXK1tS"
   },
   "source": [
    "Import all the libraries required for this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UBHHqPy2lE0L"
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.backends.cudnn as cudnn\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import pandas as pd\n",
    "import requests\n",
    "import io\n",
    "import urllib.parse\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import functools\n",
    "from PIL import Image  # Image utilities.\n",
    "import tqdm\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import imageio as io_temp\n",
    "from skimage.transform import resize\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score, classification_report, confusion_matrix\n",
    "\n",
    "\n",
    "cudnn.benchmark = True\n",
    "plt.ion()   # interactive mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_8KkHItyK7EI"
   },
   "source": [
    "Downloading the dataset from online resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wA_fHgODZqE0",
    "outputId": "53419230-3a89-4a93-eed1-f50152b6dd2b"
   },
   "outputs": [],
   "source": [
    "SOURCE_URL = 'https://storage.googleapis.com/dm-turtle-recall/images.tar'\n",
    "IMAGE_DIR = './turtle_recall/images'\n",
    "TAR_PATH = os.path.join(IMAGE_DIR, os.path.basename(SOURCE_URL))\n",
    "EXPECTED_IMAGE_COUNT = 13891\n",
    "\n",
    "%sx mkdir --parents \"{IMAGE_DIR}\"\n",
    "if len(os.listdir(IMAGE_DIR)) != EXPECTED_IMAGE_COUNT:\n",
    "  %sx wget --no-check-certificate -O \"{TAR_PATH}\" \"{SOURCE_URL}\"\n",
    "  %sx tar --extract --file=\"{TAR_PATH}\" --directory=\"{IMAGE_DIR}\"\n",
    "  %sx rm \"{TAR_PATH}\"\n",
    "\n",
    "print(f'The total number of images is: {len(os.listdir(IMAGE_DIR))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uapoX2flaGEG"
   },
   "outputs": [],
   "source": [
    "BASE_URL = 'https://storage.googleapis.com/dm-turtle-recall/'\n",
    "\n",
    "\n",
    "def read_csv_from_web(file_name):\n",
    "  url = urllib.parse.urljoin(BASE_URL, file_name)\n",
    "  content = requests.get(url).content\n",
    "  return pd.read_csv(io.StringIO(content.decode('utf-8')))\n",
    "\n",
    "# Read in csv files.\n",
    "train = read_csv_from_web('train.csv')\n",
    "test = read_csv_from_web('test.csv')\n",
    "extra = pd.read_csv('extra_images_common_updated.csv')\n",
    "sample_submission = read_csv_from_web('sample_submission.csv')\n",
    "\n",
    "# Convert image_location strings to lowercase.\n",
    "for df in [train, test]:\n",
    "  df.image_location = df.image_location.apply(lambda x: x.lower())\n",
    "  assert set(df.image_location.unique()) == set(['left', 'right', 'top'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "d-czhL74aKCA",
    "outputId": "aa296857-c78b-4839-96d8-c1f4e50b9bc6"
   },
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "xFMvi9VQaLGY",
    "outputId": "45f6d50d-2e91-4784-c035-b7d9a79bb621"
   },
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "xwy3KtkEhbTR",
    "outputId": "b58abe02-c250-4b76-ead0-f3b68ea12256"
   },
   "outputs": [],
   "source": [
    "extra.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gJ3QJpFuaNQR",
    "outputId": "6ccb156b-9886-43ab-9763-5a15b2ebfc09"
   },
   "outputs": [],
   "source": [
    "train.shape, test.shape, extra.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_mTpIevBaPsn",
    "outputId": "aff09251-983e-41f8-b151-4cae69c49c62"
   },
   "outputs": [],
   "source": [
    "print(f\"There are {train.turtle_id.nunique()} unique turtles in the train set.\")\n",
    "print(f\"There are {extra.turtle_id.nunique()} unique turtles in the train set.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KlgyH88OaRDk"
   },
   "outputs": [],
   "source": [
    "train_images_per_turtle = pd.value_counts(train['turtle_id'])\n",
    "extra_images_per_turtle = pd.value_counts(extra['turtle_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V_j6qTcUaSZo",
    "outputId": "79233e8e-dd8f-4527-9795-b4f2d3bec89c"
   },
   "outputs": [],
   "source": [
    "train_images_per_turtle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7FNRSo-LhzbH",
    "outputId": "2e6b6623-0945-4dc9-b432-793ab257c535"
   },
   "outputs": [],
   "source": [
    "extra_images_per_turtle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nbN_rb3ELPDS"
   },
   "source": [
    "Capturing all the turtle IDs and assigning a number to each turtle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hg0Zy1Mx4mrs"
   },
   "outputs": [],
   "source": [
    "ls = pd.unique(train['turtle_id'])\n",
    "classes = {}\n",
    "for i in range(len(ls)):\n",
    "    classes[ls[i]] = i\n",
    "class_names = classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qt3zsFr-A-bM",
    "outputId": "13cc9887-6c8b-4046-c841-81f6f2d7de1b"
   },
   "outputs": [],
   "source": [
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RCI84TQY27e3"
   },
   "outputs": [],
   "source": [
    "num_classes = len(class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oEM_4Va0WD_z"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B6vuZ1wpWezi"
   },
   "outputs": [],
   "source": [
    "train = pd.concat([train, extra], ignore_index=True, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "Peeob9ArWhY4",
    "outputId": "e6d14fc6-3359-4864-fe86-d90b7cb5ac06"
   },
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dkrKdadd3O7K",
    "outputId": "bda53add-652f-4dce-dd48-5d7e856c3168"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train[['image_id','image_location']], train['turtle_id'], test_size=0.20, random_state=42, stratify=train['turtle_id'])\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.50, random_state=42, stratify=y_test)\n",
    "\n",
    "print(X_train.shape, X_test.shape, X_val.shape ,y_train.shape, y_test.shape, y_val.shape)\n",
    "\n",
    "train_ds = pd.concat([X_train, y_train], axis=1)\n",
    "train_ds['type'] = \"train\"\n",
    "test_ds = pd.concat([X_test, y_test], axis=1)\n",
    "test_ds['type'] = \"test\"\n",
    "val_ds = pd.concat([X_val, y_val], axis=1)\n",
    "val_ds['type'] = \"val\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yI3brvFt4msD"
   },
   "outputs": [],
   "source": [
    "dataset_sizes = {'train': len(train_ds), 'test': len(test_ds), 'val': len(val_ds)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "cM28Kivt-CgO",
    "outputId": "6d646f55-dfba-4dcf-8b5d-acaa652c8cc9"
   },
   "outputs": [],
   "source": [
    "train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1LBlW_K1_fOD"
   },
   "outputs": [],
   "source": [
    "dataset = pd.concat([train_ds,test_ds,val_ds], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "prucJ_Ct_wDn",
    "outputId": "ce234225-77ef-4403-be1b-16dd2fbc2766"
   },
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xv1uasWbAEcZ"
   },
   "outputs": [],
   "source": [
    "dataset['image_id'] = IMAGE_DIR + \"/\" + dataset['image_id'].astype(str) + \".JPG\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DPaVsAr4LZm5"
   },
   "source": [
    "Replacing the turtle IDs with numbers for easier training by the deep learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l99rkFbytN-n"
   },
   "outputs": [],
   "source": [
    "dataset['turtle_id'] = dataset['turtle_id'].map(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0E1kopnqZSCC"
   },
   "outputs": [],
   "source": [
    "dataset.to_csv('./dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NIoMcNXwAYuZ"
   },
   "outputs": [],
   "source": [
    "train_ds = dataset.loc[dataset['type'] == \"train\"]\n",
    "train_ds = dataset.loc[dataset['image_location'] == \"right\"]\n",
    "test_ds = dataset.loc[dataset['type'] == \"test\"]\n",
    "test_ds = dataset.loc[dataset['image_location'] == \"right\"]\n",
    "val_ds = dataset.loc[dataset['type'] == \"val\"]\n",
    "val_ds = dataset.loc[dataset['image_location'] == \"right\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "5awhf_IrAx1-",
    "outputId": "ee557b46-4ce0-4208-9820-06fdd7f6b860"
   },
   "outputs": [],
   "source": [
    "train_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JET34lPoLhYY"
   },
   "source": [
    "Creating a Dataloader for our dataset which can be used for pytorch. This only makes use of the image data and the turtle ID. The turtles head orientation is not used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4585evc5PSr9"
   },
   "outputs": [],
   "source": [
    "class TurtleDataset(Dataset):\n",
    "    \"\"\"Turtle dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, csv_file, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.csv = csv_file\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.csv)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        img_name = self.csv.iloc[idx, 0]\n",
    "        image = io_temp.imread(img_name)\n",
    "        details = self.csv.iloc[idx, 1:]\n",
    "        details = np.array([details])\n",
    "        details = details[:1]\n",
    "        sample = {'image': image, 'image_orientation': details[0][0], 'turtle_id': details[0][1]}\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PLXnh8E9RbHE"
   },
   "outputs": [],
   "source": [
    "def show_pics(image, image_orientation, turtle_id):\n",
    "    plt.imshow(image)\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 501
    },
    "id": "AhW-n5mmP1ng",
    "outputId": "1515812f-9ddd-4be6-c1ce-25687564f915"
   },
   "outputs": [],
   "source": [
    "face_dataset = TurtleDataset(csv_file=train_ds)\n",
    "\n",
    "fig = plt.figure()\n",
    "\n",
    "for i in range(len(face_dataset)):\n",
    "    sample = face_dataset[i]\n",
    "\n",
    "    print(i, sample['image'].shape, sample['turtle_id'])\n",
    "\n",
    "    ax = plt.subplot(1, 4, i + 1)\n",
    "    plt.tight_layout()\n",
    "    ax.set_title('Sample #{}'.format(i))\n",
    "    ax.axis('off')\n",
    "    show_pics(**sample)\n",
    "\n",
    "    if i == 3:\n",
    "        plt.show()\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0lH42myNLtbc"
   },
   "source": [
    "Rescale helps reformat the image by changing its dimensions and cropping it to allow it to be used as an input in our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QNDcMnZDbaWo"
   },
   "outputs": [],
   "source": [
    "class Rescale(object):\n",
    "    \"\"\"Rescale the image in a sample to a given size.\n",
    "\n",
    "    Args:\n",
    "        output_size (tuple or int): Desired output size. If tuple, output is\n",
    "            matched to output_size. If int, smaller of image edges is matched\n",
    "            to output_size keeping aspect ratio the same.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, output_size = 224):\n",
    "        assert isinstance(output_size, (int, tuple))\n",
    "        self.output_size = output_size\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image, turtle_id = sample['image'],  sample['turtle_id'] \n",
    "        # image, image_orientation = sample['image'], sample['image_orientation']\n",
    "\n",
    "        h, w = image.shape[:2]\n",
    "        crop_size = min(w, h)\n",
    "        crop = image[(h - crop_size) // 2 : (h + crop_size) // 2, (w - crop_size) // 2 : (w + crop_size) // 2]\n",
    "        img = resize(crop, (self.output_size, self.output_size))\n",
    "\n",
    "        # return {'image': img, 'turtle_id': turtle_id}\n",
    "        return [img.transpose((2,0,1)).astype(np.double),turtle_id]\n",
    "        # return [img.transpose((2,0,1)).astype(np.double),image_orientation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9_mv2FI1bfht"
   },
   "outputs": [],
   "source": [
    "scale = Rescale(256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p9_xZtOxgiN7"
   },
   "outputs": [],
   "source": [
    "train_transformed_dataset = TurtleDataset(csv_file=train_ds,\n",
    "                                               transform=transforms.Compose([\n",
    "                                               Rescale(256)\n",
    "                                           ]))\n",
    "test_transformed_dataset = TurtleDataset(csv_file=test_ds,\n",
    "                                               transform=transforms.Compose([\n",
    "                                               Rescale(256)\n",
    "                                           ]))\n",
    "val_transformed_dataset = TurtleDataset(csv_file=val_ds,\n",
    "                                               transform=transforms.Compose([\n",
    "                                               Rescale(256)\n",
    "                                           ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f3wuRDMeg7lm"
   },
   "outputs": [],
   "source": [
    "dataloaders = {'train' : DataLoader(train_transformed_dataset, batch_size=16,\n",
    "                        shuffle=True, num_workers=2),\n",
    "              'test' : DataLoader(test_transformed_dataset, batch_size=16,\n",
    "                        shuffle=True, num_workers=2),\n",
    "              'val' : DataLoader(val_transformed_dataset, batch_size=16,\n",
    "                        shuffle=True, num_workers=2)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 148
    },
    "id": "pm-kCmbVwcbe",
    "outputId": "2bab69f8-2026-43c8-bd98-01738877442b"
   },
   "outputs": [],
   "source": [
    "def imshow(inp, title=None):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
    "\n",
    "\n",
    "# Get a batch of training data\n",
    "inputs, classes = next(iter(dataloaders['train']))\n",
    "\n",
    "# Make a grid from batch\n",
    "out = torchvision.utils.make_grid(inputs)\n",
    "\n",
    "imshow(out, title=classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RdDxDGF2L-Vk"
   },
   "source": [
    "train_model is a funciton to train any model with any criterion and optimizer. We can change the model input with other pretrained models to experiment further!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "20kaKUCABb4K"
   },
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                #inputs = inputs.type(torch.LongTensor)\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs.float())\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VypSd5Lqt9Ol"
   },
   "outputs": [],
   "source": [
    "def visualize_model(model, num_images=6):\n",
    "    was_training = model.training\n",
    "    model.eval()\n",
    "    images_so_far = 0\n",
    "    fig = plt.figure()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (inputs, labels) in enumerate(dataloaders['val']):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs.float())\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            for j in range(inputs.size()[0]):\n",
    "                images_so_far += 1\n",
    "                ax = plt.subplot(num_images//2, 2, images_so_far)\n",
    "                ax.axis('off')\n",
    "                ax.set_title('predicted: {}'.format(class_names[preds[j]]))\n",
    "                imshow(inputs.cpu().data[j])\n",
    "\n",
    "                if images_so_far == num_images:\n",
    "                    model.train(mode=was_training)\n",
    "                    return\n",
    "        model.train(mode=was_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PlBjxA7uuJ3_"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kMo9qm_4zRN8",
    "outputId": "b38e9c6e-952a-4a0e-a2ed-71da47eadf30"
   },
   "outputs": [],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 66,
     "referenced_widgets": [
      "5907e1edcccd46958eb627712ec6727e",
      "1857d87f7e744bd59e1f1683cd7bcd17",
      "1890a6f2be4645fc9bb279a83b8e9545",
      "a6c78237c286471ab60e4947af173317",
      "2f4c4c1ed1e947d08d4b5ed85e88ead6",
      "50e09a3cb2084437ad06c1e024066a7d",
      "60a0e184124b43a0a8f31fff600838d7",
      "ecaaa8496e6e46298595ed2a8ccb9e0e",
      "1c520ebfefef4ea7aa777d5d5f1c966b",
      "cd5937678baf4a14b731bdbb672795ee",
      "881c06c3950b46659539cb2d17c6fb56"
     ]
    },
    "id": "qPizP55RuCm1",
    "outputId": "f7ea8fe8-3e71-4a73-9d7a-c2109bbc3d79"
   },
   "outputs": [],
   "source": [
    "model_ft = models.resnet18(pretrained=True, progress=True) ### Can change this to try out other models available \n",
    "num_ftrs = model_ft.fc.in_features\n",
    "# Here the size of each output sample is set to 2.\n",
    "# Alternatively, it can be generalized to nn.Linear(num_ftrs, len(class_names)).\n",
    "model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
    "\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SEaD7GDYyT8N"
   },
   "outputs": [],
   "source": [
    "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n",
    "                       num_epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1EWNZHdwX4LE"
   },
   "outputs": [],
   "source": [
    "torch.save(model_ft.state_dict(),\"turtle_new_right.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "8XNRD2C9D3aZ"
   },
   "outputs": [],
   "source": [
    "def apk(actual, predicted, k=5):\n",
    "  \"\"\"Computes the average precision at k.\n",
    "\n",
    "  Args:\n",
    "    actual: The turtle ID to be predicted.\n",
    "    predicted : A list of predicted turtle IDs (order does matter).\n",
    "    k : The maximum number of predicted elements.\n",
    "\n",
    "  Returns:\n",
    "    The average precision at k.\n",
    "  \"\"\"\n",
    "  if len(predicted) > k:\n",
    "    predicted = predicted[:k]\n",
    "\n",
    "  score = 0.0\n",
    "  num_hits = 0.0\n",
    "\n",
    "  for i, p in enumerate(predicted):\n",
    "    if p == actual and p not in predicted[:i]:\n",
    "      num_hits += 1.0\n",
    "      score += num_hits / (i + 1.0)\n",
    "\n",
    "  return score\n",
    "\n",
    "\n",
    "def mapk(actual, predicted, k=5):\n",
    "  \"\"\" Computes the mean average precision at k.\n",
    "\n",
    "    The turtle ID at actual[i] will be used to score predicted[i][:k] so order\n",
    "    matters throughout!\n",
    "\n",
    "    actual: A list of the true turtle IDs to score against.\n",
    "    predicted: A list of lists of predicted turtle IDs.\n",
    "    k: The size of the window to score within.\n",
    "\n",
    "    Returns:\n",
    "      The mean average precision at k.\n",
    "  \"\"\"\n",
    "  return np.mean([apk(a, p, k) for a, p in zip(actual, predicted)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "1NRgDhoCBdRW"
   },
   "outputs": [],
   "source": [
    "def test_model(model, criterion, optimizer, scheduler):\n",
    "\n",
    "    model.eval()   # Set model to evaluate mode\n",
    "\n",
    "    t_output = []\n",
    "    t_pred = []\n",
    "    y_test = []\n",
    "    top_k = []\n",
    "    # Iterate over data.\n",
    "    i = 1\n",
    "    for inputs, labels in dataloaders['test']:\n",
    "        # inputs = inputs.type(torch.DoubleTensor)\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.type(torch.LongTensor)\n",
    "        labels = labels.to(device)\n",
    "        y_test.append(labels)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward\n",
    "        # track history if only in train\n",
    "        with torch.set_grad_enabled(True):\n",
    "            outputs = model(inputs.float())\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            loss = criterion(outputs, labels)\n",
    "            t_output.append(outputs)\n",
    "            t_pred.append(preds)\n",
    "            temp1, temp2 = outputs.topk(5)\n",
    "            top_k.append(temp2)\n",
    "\n",
    "        i+=1\n",
    "        if i == 11:\n",
    "            break\n",
    "    \n",
    "    y_test = torch.cat(y_test).cpu().detach().numpy() \n",
    "    y_test_num = torch.cat(t_pred).cpu().detach().numpy() \n",
    "    y_pred = torch.cat(top_k).cpu().detach().numpy() \n",
    "    mapk_result = mapk(y_test, y_pred, k=5)\n",
    "    print(\"With real set labels, our mapk with k=5 is\", mapk_result)\n",
    "    print('\\nConfusion Matrix')\n",
    "    conf_mt = confusion_matrix(y_test_num, y_test)\n",
    "    print(conf_mt)\n",
    "    plt.matshow(conf_mt)\n",
    "    plt.show()\n",
    "    print('\\nClassification Report')\n",
    "    print(classification_report(y_test_num, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "telFbCPoCPwT"
   },
   "outputs": [],
   "source": [
    "test_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "75p0fmF6yapP"
   },
   "outputs": [],
   "source": [
    "def pred(model, criterion, optimizer, scheduler):\n",
    "\n",
    "    model.eval()   # Set model to evaluate mode\n",
    "\n",
    "    t_output = []\n",
    "    t_pred = []\n",
    "    y_test = []\n",
    "    top_k = []\n",
    "    # Iterate over data.\n",
    "    i = 1\n",
    "    for inputs, labels in dataloaders['extra']:\n",
    "        # inputs = inputs.type(torch.DoubleTensor)\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.type(torch.LongTensor)\n",
    "        labels = labels.to(device)\n",
    "        y_test.append(labels)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward\n",
    "        # track history if only in train\n",
    "        with torch.set_grad_enabled(True):\n",
    "            outputs = model(inputs.float())\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            print(labels)\n",
    "            loss = criterion(outputs, labels)\n",
    "            t_output.append(outputs)\n",
    "            t_pred.append(preds)\n",
    "            temp1, temp2 = outputs.topk(5)\n",
    "            top_k.append(temp2)\n",
    "        print(preds)\n",
    "        i+=1\n",
    "        if i == 50:\n",
    "            break\n",
    "\n",
    "\n",
    "    print(t_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 165
    },
    "id": "bSldXSA53d7V",
    "outputId": "c8860633-e61f-4a8b-989b-4cd61acd0433",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pred(model_ft, criterion, optimizer_ft, exp_lr_scheduler)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Pytorch_turtle_extra_right.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "1857d87f7e744bd59e1f1683cd7bcd17": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_50e09a3cb2084437ad06c1e024066a7d",
      "placeholder": "​",
      "style": "IPY_MODEL_60a0e184124b43a0a8f31fff600838d7",
      "value": "100%"
     }
    },
    "1890a6f2be4645fc9bb279a83b8e9545": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ecaaa8496e6e46298595ed2a8ccb9e0e",
      "max": 46830571,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_1c520ebfefef4ea7aa777d5d5f1c966b",
      "value": 46830571
     }
    },
    "1c520ebfefef4ea7aa777d5d5f1c966b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "2f4c4c1ed1e947d08d4b5ed85e88ead6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "50e09a3cb2084437ad06c1e024066a7d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5907e1edcccd46958eb627712ec6727e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_1857d87f7e744bd59e1f1683cd7bcd17",
       "IPY_MODEL_1890a6f2be4645fc9bb279a83b8e9545",
       "IPY_MODEL_a6c78237c286471ab60e4947af173317"
      ],
      "layout": "IPY_MODEL_2f4c4c1ed1e947d08d4b5ed85e88ead6"
     }
    },
    "60a0e184124b43a0a8f31fff600838d7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "881c06c3950b46659539cb2d17c6fb56": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a6c78237c286471ab60e4947af173317": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cd5937678baf4a14b731bdbb672795ee",
      "placeholder": "​",
      "style": "IPY_MODEL_881c06c3950b46659539cb2d17c6fb56",
      "value": " 44.7M/44.7M [00:00&lt;00:00, 134MB/s]"
     }
    },
    "cd5937678baf4a14b731bdbb672795ee": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ecaaa8496e6e46298595ed2a8ccb9e0e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}